### The Design Philosophy of the DARPA Internet Protocols （综述探讨性）

1. DARPA互联网架构的最高目标是开发一种有效的技术，用于现有互连网络的多路复用利用。因特网的基本结构:一种分组交换通信设施，其中许多可区分的网络使用称为网关的分组通信处理器连接在一起，网关实现了一种存储和转发分组转发算法。
2. 提出网络体系构建的更详细的七条定义，下面分组解读。

3. 面对失败的生存能力：
- 这方面最重要的目标是，即使网络和网关失效，互联网也应该继续提供通信服务，即发生中断通信实体能继续通信而无需重新建立。该体系结构中假设同步永远不丢失，除非没有可以实现任何通信的物理路径。换句话说，在传输的顶部只有完全分区(total partition)故障。该体系结构完全掩盖了任何短暂的故障。
- 为实现这一目标，底层需要维护传输的数据包数量、确认的数据包数量或未完成的流控制权限的数量，且确保不会发生丢失上述信息的中断。
- 防止底层数据丢失可采取复制，命运共享的方式。复制由于其分布式性质，确保健壮复制的算法很难构建，具有分布式状态信息的网络，很少能够提供任何类型的故障保护。这里详述命运共享。
- 命运共享则具有两大优势：能防止任意数量的中间故障，而复制只能防止一定数量的故障(小于复制副本的数量)；其次，实现上容易得多。
- 命运共享方法有两个后果：首先，分组交换节点(或网关)不能有任何正在进行的连接的基本状态信息，它们是无状态分组交换机，这类网络设计有时被称为“数据报”网络。其次，更多的信任放在主机上，而不是放在网络确保可靠传递的架构上。如果确保数据排序和确认的主机驻留算法失败，则该机器上的应用程序将无法运行。
- 尽管生存能力是列表中的第一个目标，但它仍然次于现有网络互连的最高目标。单一的多媒体网络设计可能会产生一种生存能力更强的技术。
4. 服务类型
- Internet体系结构的第二个目标是在传输层支持各种类型的服务。不同类型的服务通过对速度、延迟和可靠性等方面的不同要求来区分。传统的服务类型是双向可靠的数据交付，有时被称为“虚拟电路”服务，适用于远程登录或文件传输等应用程序，其中远程登录需要低延迟交付服务，但对带宽的要求很低，而文件传输则不太关心延迟，但非常关心高吞吐量，TCP同时提供两种类型服务。TCP最初追求足够通用，支持任何所需类型的服务。然而，随着服务的全部范围变得清晰，在一个协议支持所有服务似乎太困难了。
- *例如，TCP不支持实时数字化语音，因为实时传输没必要坚持每个字节按序交付，而且，信息包必须定期到达接收机，以便被转换回模拟信号。如果没有在预期的时间到达就不可能实时重新组装信号。网络中最严重的延迟来源是提供可靠交付的机制。典型的可靠传输协议通过请求重传并延迟任何后续数据包的发送来响应丢失的数据包，直到重新传输丢失的数据包。然后它按顺序传递该数据包和所有剩余的数据包。当这种情况发生时，延迟可能是网络往返交付时间的许多倍，并可能完全破坏语音重组算法。相反，它很容易处理偶尔丢失的数据包：缺失的语音用短时间的沉默代替。在大多数情况下，这并不影响听者对语音的理解。如果出现这种情况，就会发生高级别的纠错，听者可以要求说话者重复受损的短语。
- 因此，在Internet体系结构发展的相当早期，就决定需要多个传输服务，同时承受限制可靠性、延迟或带宽的传输。这一目标导致TCP，IP分为两层，TCP提供可靠的有序数据流，而IP试图提供一个基本的构建块（数据包）构建各种服务。事实证明，在没有底层网络的明确支持的情况下提供多种类型的服务比最初希望的要困难得多，特定的网络设计不够灵活，无法支持其他服务。最常见的是，网络在设计时假定它应该提供可靠的服务，并且将延迟作为提供可靠服务的一部分，无论是否需要这种可靠性。
5. 网络的种类
- ^互联网架构的成功非常重要，因为它能够融合和利用各种各样的网络技术，包括军事和商业设施。互联网架构在实现这一目标方面非常成功;它在各种各样的网络上运行，包括长途网络(阿帕网本身和各种X.25网络)、局域网(以太网、ringnet等)、广播卫星网络(DARPA大西洋卫星网络14、15以每秒64千比特的速度运行，DARPA实验宽带卫星网络16在美国境内以每秒3兆比特的速度运行)、分组无线网络(DARPA分组无线网络、以及一个实验性的英国分组无线网络和一个由业余无线电操作员开发的网络)，各种串行链路，范围从1200 ACM SIGCOMM -5-计算机通信审查比特每秒异步连接到T1链路，以及各种其他临时设施，包括计算机间总线和其他网络套件(如IBM的HASP)的高级层提供的传输服务。
- 有许多服务没有明确地从网络中假设。这些包括可靠的或有序的传递、网络级广播或组播、传输数据包的优先级排序、对多种类型服务的支持以及对故障、速度或延迟的内部知识。如果需要这些服务，那么为了适应Internet中的网络，就需要网络直接支持这些服务，或者网络接口软件提供增强功能，以在网络端点模拟这些服务。有人认为这是一种不可取的方法，因为必须为每个网络以及每个网络的每个主机接口重新设计和实现这些服务。通过在传输过程中设计这些服务，例如通过TCP进行可靠的交付，工程只需要完成一次，并且每个主机的实现也只需要完成一次。在此之后，新网络接口软件的实现通常非常简单。
6. 其他目标 
- 对因特网进行分布式管理的目标在某些方面已经实现了。例如，因特网中有几个不同的管理中心，每个中心操作网关的一个子集，并且有一个两层路由算法，允许来自不同管理中心的网关交换路由表，即使它们彼此不完全信任，并且在单个管理中心的网关之间使用各种私有路由算法。类似地，管理网关的各种组织不一定是管理网关所连接的网络的同一组织。然而路由方面缺少足够分布式管理工具，需手动设路由表，容易出错且不强大。
- 数据包1000可靠字节40头部字节，短数据包相对于1000字节大包，后者开销4%而前者可能较大。丢失数据包重传也是低效原因之一，数据包可能二次穿过几个中间网络。但是在重传率足够低的情况下可以容忍（粗略估计，1%合理，10%应该对网络添加可靠性增强）
- ^主机连接Internet成本可能比在其他体系结构中要高一些，因为提供所需服务类型的所有机制，例如确认和重传ACM SIGCOMM -6-计算机通信审查策略，都必须在主机中而不是在网络中实现。最初，对于不熟悉协议实现的程序员来说，这样做似乎有点令人生畏。实现者尝试了诸如将传输协议移动到前端处理器等事情，他们的想法是协议只实现一次，而不是针对每种类型的主机再次实现。然而，这需要发明一个主机前端协议，有些人认为实现起来几乎和原来的传输协议一样复杂。随着协议经验的增加，与在主机中实现协议套件相关的焦虑似乎正在减少，现在可以在各种机器上实现协议套件，包括个人计算机和其他计算资源非常有限的机器。
7. 架构和实现
- 因特网架构尝试不限制服务范围。因而理解因特网不能关注架构，而必须关注特定主机和网关内软件的实际工程，以及已被合并的特定网络。
- 因特网一些实现以ms为单位，另一些以s为单位，某些应用程序(如实时语音)在这两种实现之间的工作方式有着根本不同，一些互联网被设计成网关和路径有很大的冗余。可生存的互联网存在故障后重新配置的资源。其他互联网为了降低成本，通过实现有单点连接，一个故障可能把它分成两部分。
- ** Internet体系结构通过设计来容忍这种实现的多样性。然而，它给特定实现的设计者留下了大量的工程工作要做。这种架构开发的主要斗争之一是理解如何为实现的设计者提供指导，这种指导将实现的工程与将产生的服务类型联系起来。例如，设计师必须回答以下问题。如果整个服务要交付某个速率的吞吐量，底层网络中必须有什么样的带宽?给定这个实现中可能出现的故障的某个模型，应该在实现中设计什么样的冗余?大多数已知的网络设计辅助工具似乎对回答这类问题没有帮助。 
  - 例如，协议验证器帮助确认协议符合规范。然而，这些工具几乎从不处理性能问题，而性能问题对于服务类型的思想是至关重要的。相反，它们处理的是协议在规范方面的逻辑正确性这个更受限制的思想。虽然用于验证逻辑正确性的工具在规范和实现阶段都很有用，但它们不能帮助解决经常出现的与性能相关的严重问题。一个典型的实现经验是，即使在证明了逻辑正确性之后，也会发现可能导致一个数量级性能下降的设计错误。对这个问题的研究得出的结论是，困难通常不是在协议本身，而是在协议运行的操作系统上。在这种情况下，很难在ACM SIGCOMM -7-计算机通信评审体系结构规范的上下文中解决这个问题。然而，我们仍然强烈地感到有必要给予实现者指导。今天我们仍在与这个问题作斗争。
  - 另一类设计辅助是模拟器，它采用特定的实现，并探索它在各种负载下可以交付的服务。还没有人尝试构造一个模拟器，它考虑到网关实现、主机实现和在可能的Internet实现中看到的网络性能的广泛可变性。因此，大多数互联网实现的分析都是在信封的背面完成的。这是对互联网架构的目标结构的评论，如果由一个足够有知识的人完成，一个信封的背面分析通常就足够了。特定Internet实现的设计人员通常不太关心获得最后5%的可能的线路利用率，而是知道在给定当前手头的资源的情况下是否可以实现所需的服务类型。
  - 架构和性能之间的关系是一个极具挑战性的关系。互联网架构设计者在将体系结构中的性能约束形式化方面遇到了很大的困难：一方面是因为体系结构的目标不是限制性能，而是允许可变性，另一方面(也许是更根本的原因)是因为似乎没有有用的形式化工具来描述性能。这个问题尤其严重，因为互联网项目的目标是产生规范文件，这些文件将成为军事标准。这是政府承包的一个众所周知的问题，人们不能期望承包商满足任何不属于采购标准的标准。因此，如果互联网关注的是性能，则必须将性能要求纳入采购规范。发明限制性能的规范是微不足道的，例如指定实现必须能够每秒传递1000个数据包。然而，这种类型的约束不能成为体系结构的一部分，因此要由执行采购的个人来认识到这些性能约束必须添加到规范中，并正确地指定它们以实现提供所需类型的服务。我们不知道如何在架构中为执行这项任务的人提供指导。
8. 数据报
- 因特网以数据报作为实体传输。首先，它们消除了中间交换节点对连接状态的需求，这意味着在故障发生后，可以在不考虑状态的情况下重新构建Internet。其次，数据报提供了一个基本的构建块，在此基础上可以实现各种类型的服务。与虚拟电路(通常意味着固定类型的服务)相比，数据报提供了更基本的服务，端点可以将其适当组合以构建所需的服务类型。第三，数据报代表了最小的网络服务假设，允许将各种各样的网络合并到各种Internet实现中。使用数据报的决定是一个非常成功的决定，这使得互联网非常成功地实现了它最重要的目标。
- 有一个与数据报相关的错误假设，即数据报的动机是对本质上等同于数据报的更高级别服务的支持。换句话说，有时建议提供数据报，因为应用程序所需的传输服务是数据报服务。事实上，这种情况很少发生。虽然Internet上的一些应用程序(例如对日期服务器或名称服务器的简单查询)使用基于不可靠数据报的访问方法，但Internet中的大多数服务更喜欢更复杂的传输模型，而不是简单的数据报。有些服务希望增强可靠性，有些希望平滑和缓冲延迟，但几乎所有服务都有一些比数据报更复杂的期望。重要的是要理解数据报在这方面的作用是作为构建块，而不是作为服务本身。
9. TCP
- $ TCP在成为标准之前经历了几个主要版本。
  - 最初的ARPANET主机到主机协议提供了基于字节和数据包的流量控制。这似乎过于复杂，TCP的设计者认为只有一种形式的监管就足够了。选择是规范字节的传递，而不是数据包。因此，TCP中的流控制和确认是基于字节数而不是数据包数。实际上，在TCP中，数据的分组化是没有意义的。 这一决定是出于若干考虑，其中一些考虑无关紧要，而另一些考虑比预期的更重要。确认字节的一个原因是允许在字节的序列空间中插入控制信息，这样就可以确认控制和数据。这种序列空间的使用被放弃了，取而代之的是处理每个控制消息的特别技术。虽然最初的想法具有吸引力的普遍性，但它在实践中造成了复杂性。
  - 字节流的第二个原因是允许TCP包在必要时被分解成更小的包，以便通过一个小包大小的网络。但是当IP从TCP中分离出来时，这个功能被转移到了IP层，IP被迫发明了一种不同的碎片化方法。
  - **确认字节而不是数据包的第三个原因是，如果需要重新传输数据，允许在发送主机中将许多小包聚集在一起成为一个较大的数据包。目前尚不清楚这种优势是否重要;事实证明，这是至关重要的。UNIX等具有基于单个字符交互的内部通信模型的系统通常会发送许多包含一个字节数据的数据包。(有人可能会从网络的角度认为这种行为很愚蠢，但这是现实，是交互式远程登录的必要条件。)人们经常观察到，这样的主机可以用一个字节的数据产生大量的数据包，这些数据包到达的速度要比慢速主机处理它们的速度快得多。结果是丢包和重传。
    - 如果重传的是原始数据包，那么在每次重传时都将重复同样的问题，从而对性能造成无法容忍的影响，从而阻止操作。但是由于字节被收集到一个数据包中进行重传，重传以一种更有效的方式发生，从而允许实际操作。另一方面，字节的确认可以被视为首先造成这个问题的原因。如果流量控制的基础是数据包而不是字节，那么这种洪泛可能永远不会发生。但是，如果发送的是小包，则包级别的控制会对吞吐量提供严格的限制：实际接收的数据报，数据量可能相差1000倍，这取决于发送主机在每个数据包中放入的字节是1个还是1000个。回顾过去，正确的设计决策可能是，如果TCP要提供对各种服务的有效支持，就必须像最初的ARPANET协议那样，对数据包和字节都进行监管。
    - 与字节流相关的另一个设计决策是字母结束标志，或EOL。现在它已经从协议中消失了，取而代之的是Push标志或PSH。EOL最初的想法是将字节流分解成记录。它是通过将来自不同记录的数据放入不同的数据包来实现的，这与重新传输时组合数据包的想法不兼容。因此，EOL的语义被更改为一种较弱的形式，仅意味着到目前为止流中的数据是一个或多个完整的应用程序级元素，这将导致TCP或网络中的任何内部缓冲刷新。通过说“一个或多个”而不是“恰好一个”，可以将几个组合在一起，并保持在重组中压缩数据的目标。但是较弱的语义意味着各种应用程序必须发明一种特别的机制来在数据流之上划分记录。在EOL语义的演变过程中，有一种鲜为人知的中间形式，这引起了很大的争论。根据主机的缓冲策略，TCP的字节流模型可能在一种不太可能的情况下造成很大的问题。考虑这样一个主机，其中传入的数据被放入一个固定大小的缓冲区序列中。缓冲区被填满时返回给用户，或者接收到EOL。现在考虑一个无序包到达的情况，它的无序程度超过了当前缓冲区。现在进一步考虑，在接收到这个乱序数据包后，一个带有EOL的数据包导致当前缓冲区只部分满地返回给用户。这个特定的操作序列会导致下一个缓冲区中的无序数据位于错误的位置，因为缓冲区中的空字节返回给用户。处理这一问题在主机中产生了簿记问题，这似乎是不必要的。为了解决这个问题，有人提出EOL应该“用完”所有的序列空间，直到下一个值，即缓冲区大小为零。换句话说，提出EOL应该是一种将字节流映射到主机缓冲区管理的工具。

10. 结论
 - 互联网架构是非常成功的。这些协议在商业和军事环境中广泛使用，并产生了许多类似的体系结构。与此同时，它的成功也清楚地表明，在某些情况下，设计师的优先级与实际用户的需求并不匹配。需要更多地注意会计、资源管理和有单独行政机构的区域的运作等问题。虽然数据报在解决Internet最重要的目标方面发挥了很好的作用，但当我们试图解决一些排在优先级列表后面的目标时，它的作用就不那么好了。例如，在数据报的情况下，资源管理和责任制的目标已证明难以实现。正如前一节所讨论的，大多数数据报是从源到目的地的某个数据包序列的一部分，而不是应用程序级别的孤立单元。然而，网关不能直接看到这个序列的存在，因为它被迫孤立地处理每个数据包。因此，必须对每个数据包分别进行资源管理决策或记帐。将数据报模型强加于互联网层已经剥夺了该层可以用来实现这些目标的重要信息来源。这表明，对于下一代体系结构，可能存在比数据报更好的构建块。此构建块的一般特征是，它将标识从源到目的地的数据包序列，而不假设该服务具有任何特定类型的服务。我用“流”这个词来描述这个构建块。为了记住通过它们的流的性质，网关有必要具有流状态，但是状态信息对于维护与流关联的所需服务类型并不重要。相反，该类型的服务将由端点强制执行，端点将定期发送消息以确保正确的服务类型与流关联。通过这种方式，与流关联的状态信息可能会在崩溃中丢失，而不会永久地中断所使用的服务功能。我把这个概念称为“软状态”，它很可能允许我们实现生存性和灵活性的主要目标，同时更好地处理资源管理和问责制问题。探索替代构建模块是DARPA互联网项目目前的研究方向之一。
### A Brief History of the Internet (综述历史性)
#### 简单梳理下时间线，论文中每句话都不冗余。 

### END-TO-END ARGUMENTS IN SYSTEM DESIGN （原理）
1. 摘要： 本文提出了一种设计原则，它有助于指导分布式计算机系统模块之间的功能布置。这一原理被称为端到端论证，它表明，与在这种低层次上提供这些功能的成本相比，位于系统低层的功能可能是多余的或价值不大。本文讨论的示例包括误码恢复、使用加密的安全性、重复消息抑制、从系统崩溃中恢复和传递确认。支持这些功能的低级机制只能作为性能增强来使用。
2. 介绍
-  功能之间设计适当的界限也许是计算机系统设计者的主要活动。为这种功能布局选择提供指导的设计原则是系统设计者最重要的工具之一。本文讨论了一类功能配置论点，它已被使用多年，既没有明确的认识，也没有多少说服力。然而，作为计算机系统组成部分的数据通信网络的出现，通过使其应用的情况和原因更加明显，使这种功能布置的论点更加尖锐。本文明确地阐述了这个论点，以便检验它的性质，并了解它究竟有多一般。该参数符合应用程序需求，并提供了在分层系统中向上移动函数的基本原理，使其更接近使用该函数的应用程序。我们首先考虑这个论点的通信网络版本。在包含通信的系统中，通常围绕通信子系统绘制模块化边界，并定义通信子系统与系统其余部分之间的牢固接口。当这样做时，很明显有一个函数列表，其中每个函数都可以以几种方式中的任何一种实现:通过通信子系统，通过其客户端，作为一个联结，每个人都在做自己的版本。在对这一选择进行推理时，应用程序的需求为一类论证提供了基础，这些论证如下:所讨论的功能只有在位于通信系统端点的应用程序的知识和帮助下才能完全正确地实现。因此，将该功能作为通信系统本身的特性是不可能的。(有时，通信系统提供的功能的不完整版本可能有助于提高性能。)我们把这种反对低级函数实现的推理称为“端到端论证”。以下部分将详细研究端到端参数，首先通过一个典型示例的案例研究来使用该参数——所讨论的函数是可靠的数据传输——然后展示可以应用相同参数的函数范围。对于数据通信系统，这个范围包括加密、重复消息检测、消息排序、有保证的消息传递、检测主机崩溃和传递收据。在更广泛的背景下，这一论点似乎适用于计算机操作系统的许多其他功能，包括它的文件系统。但是，如果我们首先考虑更具体的数据通信上下文，那么对这个更广泛的上下文的检查将更容易。

3. 端到端看护
- 考虑一下“小心文件传输”的问题。文件由文件系统存储在计算机A的磁盘存储器中。计算机A通过数据通信网络与计算机B连接，计算机B也具有文件系统和磁盘存储器。目标是将文件从计算机A的存储器中无损地移到计算机B的存储器中，因为我们知道在这个过程中的各个点都可能发生故障。本例中的应用程序是文件传输程序，该程序一部分运行在主机A上，另一部分运行在主机b上。为了讨论在此事务中可能对文件完整性造成的威胁，我们假设涉及以下具体步骤:在主机A上，文件传输程序调用文件系统从磁盘读取文件，文件系统将文件以固定大小的块(选择与磁盘格式无关)的形式传递给文件传输程序。同样在主机A上，文件传输程序要求数据通信系统使用某种包括将数据分成包的通信协议来传输文件。数据包大小通常不同于文件块大小和磁盘轨道大小。
  - 数据通信网将数据包从计算机A传送到计算机B。
  - 在主机B上，数据通信程序从数据通信协议中删除数据包，并将包含的数据交给文件传输应用程序的第二部分，即在主机B内操作的部分。
  - 在主机B上，文件传输程序要求文件系统将接收到的数据写到主机B的磁盘上。
- 有了这个模型所涉及的步骤，下面是一些对事务的威胁，一个细心的设计者可能会关注:
   - 该文件，虽然最初正确地写入到主机A的磁盘上，但如果现在读取可能包含不正确的数据，这可能是由于磁盘存储系统中的硬件故障。
  - 文件系统软件、文件传输程序或数据通信系统可能在主机a或主机B上缓冲和复制文件数据时出错。
  - 硬件处理器或其本地内存在主机a或主机B进行缓冲和复制时可能会出现短暂错误。
  - 通信系统可能会丢失或改变一个包中的位，或者丢失一个包，或者多次传送一个包。
  - 任何一个主机在执行未知数量(可能是全部)的事务后，都可能在事务执行的中途崩溃。

那么，一个谨慎的文件传输应用程序如何应对这些威胁呢?一种方法可能是使用副本、超时和重试、仔细定位冗余以进行错误检测、崩溃恢复等方法来加强过程中的每个步骤。目标是将每种威胁的概率降低到一个可接受的小值。不幸的是，系统地对抗威胁二需要编写正确的程序，这是一项相当困难的任务，而且并非所有必须正确的程序都是由文件传输应用程序程序员编写的。如果我们进一步假设所有这些威胁的概率都相对较低——低到系统允许完成有用的工作——那么像将所有事情重复三次这样的强力对策就显得不经济了。

另一种方法可以称为“端到端检查并重试”。假设作为应对第一个威胁的辅助手段，每个文件都存储了一个校验和，该校验和具有足够的冗余，可以将文件中未检测到错误的几率降低到可接受的可忽略不计的值。应用程序按照上面简单的步骤将文件从A传输到B。然后，作为最后的附加步骤，位于主机B的文件传输应用程序的一部分将传输的文件副本从其磁盘存储系统读入自己的内存，重新计算校验和，并将这个值发送回主机A，在那里将其与原始文件的校验和进行比较。只有当两个校验和一致时，文件传输应用程序才声明事务已提交。如果比较失败，说明出现了问题，可能会尝试从头重试。

如果失败的情况很少发生，这种方法通常在第一次尝试时就会奏效;有时可能需要第二次甚至第三次尝试;人们可能会认为在同一个文件传输尝试中出现两次或两次以上的失败，这表明系统的某些部分需要修复。

现在让我们考虑一个共同的建议，即通信系统在内部提供可靠数据传输的保证。例如，它可以通过以包校验和、序列号检查和内部重试机制的形式提供选择性冗余来实现这一保证。只要足够小心，未检测到误码的概率可以降低到任何理想的水平。问题是，这种试图在通信系统方面有所帮助的尝试是否对谨慎的文件传输应用程序有用。

答案是，第4个威胁可能已经消除，但是小心的文件传输应用程序仍然必须对抗剩余的威胁，因此它仍然应该根据文件的端到端校验和提供自己的重试。如果这样做，在通信系统中为提供可靠数据传输的保证而花费的额外精力只会减少文件传输应用程序的重试频率;它对结果的必然性或正确性没有影响，因为正确的文件传输是由端到端校验和和重试来保证的，无论数据传输系统是否特别可靠。

因此，论点是:为了实现仔细的文件传输，执行传输的应用程序必须提供特定于文件传输的端到端可靠性保证——在这种情况下，是检测失败的校验和和重试/提交计划。对于数据通信系统来说，不遗余力地追求极高的可靠性并不能减轻应用程序确保可靠性的负担。

最近在麻省理工学院(mit)出现了一个有趣的陷阱例子:一个涉及多个由网关连接的本地网络的网络系统在从一个网关到下一个网关的每一跳上都使用了数据包校验和，假设正确通信的主要威胁是传输过程中的比特损坏。应用程序程序员，了解这个校验和假设网络提供了可靠的传输，而没有意识到传输的数据存储在每个网关时是不受保护的。一台网关计算机出现了瞬时错误，在将数据从输入缓冲区复制到输出缓冲区时，一个字节对发生了交换，这种交换的频率大约为每百万字节传递一次。在一段时间内，操作系统的许多源文件通过有缺陷的网关反复传输。其中一些源文件因字节交换而损坏，它们的所有者被迫进行最终的端到端错误检查:手动与旧清单进行比较并更正。

然而，如果得出结论说较低的级别在获得可靠性方面不起作用，那就太简单了。考虑一个有点不可靠的网络，每发送100个消息就丢失一个消息。上面概述的简单策略，即传输文件，然后检查文件是否正确到达，随着文件长度的增加，执行效果会更差。一个文件的所有数据包正确到达的概率随着文件长度的增加呈指数下降，因此传输文件的预期时间也会随着文件长度的增加呈指数增长。显然，在较低级别上改进网络可靠性的一些工作可以对应用程序性能产生重大影响。但这里的关键思想是，较低的级别不需要提供“完美”的可靠性。

因此，在数据通信系统中投入可靠性度量的工作量被视为基于性能的工程权衡，而不是对正确性的要求。注意，这里的性能有几个方面。如果通信系统太不可靠，文件传输应用程序的性能将受到影响，因为端到端校验和失败后会频繁重试。如果通信系统通过内部可靠性措施得到加强，这些措施也会有性能成本，表现为冗余数据造成的带宽损失，以及在交付数据之前等待内部一致性检查完成而增加的延迟。如果考虑到无论通信系统变得多么可靠，文件传输应用程序的端到端检查仍然必须实现，那么几乎没有理由在这个方向上走得太远。“适当的”权衡需要仔细思考;例如，可以从设计通信系统开始，只提供成本和工程工作很少的可靠性，然后评估剩余错误级别，以确保它与文件传输级别上可接受的重试频率一致。在应用程序级别以下的任何一点上努力实现可以忽略不计的错误率可能并不重要。

必须谨慎地使用性能来证明在低级子系统中放置功能的合理性。

有时，通过彻底检查问题，可以在高层实现相同或更好的性能增强。如果在低级别执行某个功能时，对已经包含在低级别子系统中的机制的扰动最小，那么在低级别执行该功能可能更有效，但可能发生相反的情况——也就是说，在较低级别执行该功能可能花费更多——原因有两个。首先，由于较低级别的子系统对于许多应用程序来说是通用的，因此那些不需要该功能的应用程序无论如何都会为它买单。其次，低级子系统可能没有高级子系统拥有那么多的信息，因此它不能有效地完成工作。

通常，性能的权衡是相当复杂的。再考虑一下在不可靠的网络上小心地传输文件。提高数据包可靠性的常用技术是使用重试协议对每个数据包进行某种错误检查。这种机制既可以在通信子系统中实现，也可以在小心的文件传输应用程序中实现。例如，在仔细的文件传输中，接收方可以定期计算到目前为止收到的文件部分的校验和，并将其传输回发送方。然后，发送方可以重新发送错误到达的任何部分来重新启动。

端到端参数并没有告诉我们在哪里进行早期检查，因为任何一层都可以进行这种性能增强工作。在文件传输应用程序中放置早期重试协议简化了通信系统，但可能会增加总体成本，因为通信系统由其他应用程序共享，每个应用程序现在必须提供自己的可靠性增强。在通信系统中放置早期重试协议可能更有效，因为它可以在网络内部逐跳执行，减少了纠正故障所涉及的延迟。同时，可能会有一些应用程序发现增强的成本不值得，但现在它在这个问题上没有选择*。为了明智地做出这一选择，需要大量关于系统实现的信息。

4. 端到端参数的其他例子
基本的观点是，支持分布式应用程序的底层子系统提供的功能本质上必须在应用程序级别实现，但除了可靠的数据传输之外，还可以应用于各种功能，这可能是在浪费精力。

也许最古老和最广为人知的论证形式与确认交付有关。数据通信网络可以很容易地将发送到接收方的每条消息返回到发送方。例如，ARPANET在发送消息时返回一个称为“请求下一个消息”(RFNM)[1]的包。尽管这种确认在网络中作为一种拥塞控制形式可能是有用的(最初ARPANET拒绝接受到同一目标的另一条消息，直到前一个RFNM返回)，但它从未被发现对使用ARPANET的应用程序有很大帮助。原因是，确定消息已传递到目标主机并不是很重要。应用程序想要知道的是目标主机是否对消息进行了操作;各种灾难可能发生在消息传递之后，但在消息请求的操作完成之前。真正需要的确认是一个端到端的确认，它只能由目标应用程序发起——“我做了”或“我没有做”。获得即时确认的另一种策略是使目标主机足够复杂，当它接受消息交付时，它还承担保证目标应用程序对消息进行操作的责任。这种方法可以在某些应用程序(但不是所有应用程序)中消除对端到端确认的需求。只有当向其他主机请求的类似操作成功时，才执行向目标主机请求的操作的应用程序仍然需要端到端确认。这种应用程序需要一个两阶段提交协议[5,10,15]，这是一个复杂的端到端确认。此外，如果目标应用程序可能失败或拒绝执行所请求的操作，因此可能会出现否定确认，则端到端确认可能仍然是必需的。

数据的安全传输端到端论点可以应用的另一个领域是数据加密。这里的论点有三个方面。首先，如果数据传输系统执行加密和解密，必须信任它来安全地管理所需的加密密钥。其次，当数据进入目标节点并分散到目标应用程序时，数据将是清晰的，因此容易受到攻击。第三，应用程序仍然必须检查消息的真实性。

如果应用程序执行端到端加密，它将获得所需的身份验证检查可以对密钥管理进行满意的处理，并且数据永远不会暴露在应用程序之外。

因此，为了满足应用程序的要求，通信子系统不需要为所有流量提供自动加密。然而，通信子系统可能需要对所有通信进行自动加密，以确保其他事情——行为不端的用户或应用程序不会故意传输不应该暴露的信息。所有数据进入网络时的自动加密是系统设计者可以使用的又一道防火墙，以确保信息不会泄露到系统之外。但是请注意，这与验证系统用户对数据特定部分的访问权限是不同的需求。这种网络级加密可能相当简单——所有主机都可以使用相同的密钥，只需频繁更改密钥。没有每个用户的密钥会使密钥管理问题复杂化。应用程序级身份验证和保护的加密使用是互补的。两种机制都不能完全满足这两个要求。

重复消息抑制可以应用更复杂的参数来抑制重复消息。某些通信网络设计的一个特性是消息或消息的一部分可能被传递两次，这通常是由于网络中运行的超时触发故障检测和重试机制造成的。网络可以提供监视和抑制任何此类重复消息的功能，也可以简单地传递它们。人们可能会认为，应用程序会发现处理可能两次传递相同消息的网络非常麻烦;这的确很麻烦。不幸的是，即使网络抑制了重复请求，应用程序本身也可能在自己的失败/重试过程中意外地产生重复请求。对于通信系统来说，这些应用程序级别的重复看起来像不同的消息，因此无法抑制它们;抑制必须由应用程序自己完成，并且知道如何检测它自己的副本。

必须在高层处理的重复抑制的一个常见示例是，当远程系统用户对缺乏响应感到困惑时，他开始对分时系统进行新的登录。

例如，大多数通信应用程序都涉及到在多站点事务的一端处理系统崩溃的规定:当崩溃的系统再次出现时重新建立事务。不幸的是，系统崩溃的可靠检测是有问题的:问题可能只是丢失或长时间延迟的确认。如果是这样，重试的请求现在是一个副本，只有应用程序可以发现它。因此，端到端论点再次出现:如果应用程序级别无论如何都必须有一个重复抑制机制，那么该机制也可以抑制通信网络内部生成的任何重复，因此该功能可以从较低的级别中省略。同样的基本推理适用于完全省略的信息以及重复的信息。

保证FIFO消息传递确保消息以相同的发送顺序到达接收者是通常分配给通信子系统的另一个功能。通常用于实现这种先进先出(FIFO)行为的机制保证了在同一虚拟电路中发送的消息之间的FIFO顺序。沿着独立的虚拟电路或通过通信子系统外的中间进程发送的消息可以以不同于发送顺序的顺序到达。在一个分布式应用程序中，一个节点可以发起在多个站点发起操作的请求，因此不能利用FIFO排序属性来保证所请求的操作以正确的顺序发生。相反，一个比通信子系统更高级别的独立机制必须控制动作的顺序。

事务管理我们现在已经在SWALLOW分布式数据存储系统[15]的构建中应用了端到端参数，它导致了开销的显著降低。SWALLOW提供了称为存储库的数据存储服务器，可以远程使用存储和检索数据。访问存储库中的数据是通过向它发送一条消息来完成的，该消息指定要访问的对象、版本和访问类型(读/写)，如果访问是写，则加上要写入的值。底层消息通信系统不抑制重复消息，因为a)对象标识符加上版本信息足以检测重复的写，b)重复的读请求消息的效果只是生成重复的响应，它很容易被发起者丢弃。因此，底层消息通信协议大大简化了。

底层消息通信系统也不提供传递确认。写请求的发起者需要确认数据已安全存储。这种确认只能由SWALLOW系统的高层提供。对于读请求，传递确认是多余的，因为包含read值的响应就是足够的确认。通过消除传递确认，传输的消息数量减少了一半。这种消息减少可以对主机负载和网络负载产生显著影响，从而提高性能。在开发远程访问磁盘记录[6]的实验协议时，也使用了相同的推理思路。在低级协议中减少路径长度对于保持远程磁盘访问的良好性能非常重要。

5. 鉴别端(identifying the ends)
使用端到端参数有时需要对应用程序需求进行细致的分析。例如，考虑一个计算机通信网络，它承载着一些分组语音连接，数字电话仪器之间的对话。对于那些携带语音包的连接，端到端论点的一个异常强烈的版本适用:如果低层通信系统试图完成位完美通信，他们可能会在包传递中引入不受控制的延迟，例如，通过请求重传损坏的包，并延迟后一个包的传递，直到早期的包正确重传。这种延迟会破坏语音应用程序，因为它需要以恒定的速率向侦听器提供数据。最好是接受轻微损坏的数据包，甚至将它们替换为静默、先前数据包的副本或噪声爆发。语音的自然冗余，以及高级的纠错程序，其中一个参与者说“不好意思，有人掉了一个杯子。你能再说一遍吗?”，如果这种情况相对不常见的话，他们会处理这种情况。

然而，这种强版本的端到端论证是特定应用程序(两个人进行实时对话)的属性，而不是一般的语音属性。如果考虑一个语音信息系统，其中语音包存储在一个文件中供接收方稍后收听，则参数突然改变了它们的性质。数据包传送到存储介质的短延迟不会造成特别的破坏，因此不再反对为实现可靠性而引入延迟的低级别可靠性措施。更重要的是，它实际上有助于这个应用程序在录制的消息中获得尽可能多的准确性，因为接收者在听录音时，将无法要求发送者重复一个句子。另一方面，当存储系统作为语音通信的接收端时，端到端的参数确实适用于分组排序和重复抑制。因此，端到端参数不是绝对规则，而是有助于应用程序和协议设计分析的指导方针;人们必须谨慎地确定该论点应适用于的终点。

本文中引用的端到端参数的个别例子不是原创的;它们是多年积累起来的。作者注意到的第一个有问题的中间交付确认的例子是麻省理工学院兼容分时系统的“等待”消息，每当用户输入命令[3]时，系统就会在用户的终端上打印该消息。(这条消息在系统的早期有一定的价值，当时崩溃和通信故障非常频繁，中间的确认提供了一些必要的保证，确保一切都很好。)与加密相关的端到端论点首次由布兰斯塔德在1973年的论文[2]中公开讨论;据推测，在此之前，军事安全部门进行过机密讨论。Diffie和Hellman[4]和Kent[8]更深入地展开了争论，Needham和Schroeder[11]为此目的设计了改进的协议。

Gray[5]、Lampson和Sturgis[10]和Reed[13]的两阶段提交数据更新协议都使用了一种端到端的参数形式来证明它们的存在;它们是端到端协议，不依赖于可靠性、FIFO排序或通信系统中的重复抑制，因为所有这些问题也可能由其他系统组件故障引起。里德在他关于分散原子作用的博士论文的第二章中明确地提出了这一论点。

端到端参数通常应用于应用程序系统中的错误控制和正确性。

例如，银行系统通常根据政策和法律要求提供高级审计程序。这些高级审计程序不仅会发现高级错误(如对错误的帐户进行提现)，还会发现低级错误(如底层数据管理系统中的协调错误)。

因此，一个完全消除这种协调错误的昂贵算法可能比一个成本更低、只使这种错误非常罕见的算法更不合适。在航空公司预订系统中，可以依靠代理不断尝试，通过系统崩溃和延迟，直到确认或拒绝预订。因此，用于保证未确认的预订请求在系统崩溃后仍然存在的低级恢复过程并不重要。在电话交换机中，可能导致单个呼叫丢失的故障被认为不值得提供显式恢复，因为如果重要的话，调用方可能会替换该呼叫[7]:所有这些设计方法都是应用于自动恢复的端到端参数的示例。

网络协议社区中关于数据报、虚拟电路和无连接协议的争论主要是关于端到端参数的争论。模块化的论点将可靠的、FIFO顺序的、重复抑制的数据流作为易于构建的系统组件，并且该论点支持虚拟电路。端到端观点认为，对于某些应用程序来说，这些函数的中央提供版本是不完整的，而这些应用程序会发现从数据报开始构建它们自己的函数版本会更容易。

非通信应用程序中端到端论点的一个版本是由系统分析人员在20世纪50年代开发的，他们的职责包括在大量磁带上读取和写入文件。定义和实现一个“可靠的磁带子系统”的反复尝试一再失败，因为脆弱的磁带驱动器、不可靠的系统操作员和系统崩溃共同破坏了所有狭隘的可靠性度量。最终，每个应用程序都提供自己的应用程序相关的检查和恢复策略，这成为了标准实践;并且假设较低级别的错误检测机制最多可以降低较高级别检查失败的频率。例如，Multics文件备份系统[17]，尽管它是建立在磁带子系统格式的基础上的提供了非常强大的错误检测和纠正功能，提供了自己的错误控制形式的记录标签和多个副本的每个文件。

用于支持精简指令集计算机(RISC)体系结构的参数类似于端到端参数。RISC的论点是，架构的客户端通过从原始工具中精确地实现所需的指令将获得更好的性能;任何计算机设计师试图预测客户对某个深奥功能的需求的尝试都可能会略微偏离目标，而客户最终还是会重新实现该功能。(我们感谢M. Satyanarayanan指出了这个例子。)Lampson在他支持“开放操作系统”的论证中，[9]使用了一个类似于端到端论证的论证。Lampson反对将任何功能作为较低级别模块的永久固定装置;该函数可以由较低级别的模块提供，但它应该总是可以被应用程序的特殊版本的函数所替换。理由是，对于您能想到的任何函数，至少有些应用程序会发现，为了正确地满足自己的需求，它们必须自己实现函数。这条推理路线导致Lampson提出了一个“开放”系统，在这个系统中，整个操作系统由来自库的可替换例程组成。这种方法直到最近才在专用于单一应用程序的计算机环境中变得可行。在这种情况下，大型操作系统典型的大量固定管理器功能可能只是经济压力的产物，需要昂贵的硬件多路复用，因此是受保护的管理器。事实上，大多数最近的系统“内核化”项目至少部分地关注于从低系统级别获得功能[16,12]。尽管这种函数移动是受到另一种正确性论证的启发，但它的副作用是产生了一个对应用程序更灵活的操作系统，而这正是端到端论证的主要目的。

6. 结论
当涉及到在通信子系统中选择要提供的函数时，端到端参数是一种“奥卡姆剃刀”。由于通信子系统通常是在知道使用该子系统的应用程序之前指定的，因此设计人员可能会试图通过承担不必要的功能来“帮助”用户。意识到端到端的争论有助于减少这种诱惑。

现在流行讨论“分层”通信协议，但没有明确定义的标准来为层分配功能。为了增强模块化，需要这样的分层。端到端的论证可以被视为组织这种分层系统的一套理性原则的一部分。我们希望我们的讨论将有助于为关于“适当”分层的争论增添实质内容。


