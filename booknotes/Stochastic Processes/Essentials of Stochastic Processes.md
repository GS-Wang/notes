#### 前言：适合有概率论，或者概率分析入门知识阅读。

- 该书初稿源于作者在康奈尔大学的授课笔记，在2009年春季，该校数学系推出新课程后，便着力准备第二版。概率论的发展是为了解决问题，这是作者个人的哲学，所以大部分努力将花在分析例子上。正如可以在不知道内燃机工作情况的情况下驾驶汽车一样，也可以在不知道证明细节的情况下应用马尔可夫链理论。

#### 第一章 马尔可夫链(Markov Chains)

事例：赌徒的毁灭
 - 考虑一个游戏，赌徒有$p = 0.4$的概率赢一美元，$p = 0.6$的概率输一美元，则一般情况表示如下：   

$$ P(X_{n+1} = i+1 | X_n = i, X_{n-1} = i_{n-1}, \ldots, X_0 = i_0) = 0.4 $$
$$ P(X_{n+1} = i-1 | X_n = i, X_{n-1} = i_{n-1}, \ldots, X_0 = i_0) = 0.6 $$

关于基础的条件概率分析，限于篇幅不赘述（可参考原书）
我们给出一般性定理：

具有转移矩阵的markov chain，如果 $p(i, j)$ 对于任意 $j, i, i_{n-1},... i0$ 有：

$$ P(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \ldots, X_0 = i_0) = p(i,j)  \tag{1.1} $$

公式 $(1.1)$ 解释了我们所说的“给定当前状态 $X_{n}$，任何其他关于过去的信息都与预测无关。

对于 $N = 5$ 而言，赌徒信息矩阵：

$$
\begin{bmatrix}
1.0 & 0 & 0 & 0 & 0 & 0 \\
0.6 & 0 & 0.4 & 0 & 0 & 0 \\
0 & 0.6 & 0 & 0.4 & 0 & 0 \\
0 & 0 & 0.6 & 0 & 0.4 & 0 \\
0 & 0 & 0 & 0.6 & 0 & 0.4 \\
0 & 0 & 0 & 0 & 0 & 1.0
\end{bmatrix}
$$

Ehrenfest chain.